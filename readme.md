# MLLM Defake: A Scalable MLLM-based AIGC Detection Model

This project implements a scalable Multi-modal Large Language Model (MLLM) based approach for detecting AI-generated content (AIGC). It provides a command-line interface through the `mllmdf` (shorthand for "MLLM Defake") CLI tool for analyzing and detecting fake images generated by AI.

## Quick Start

```bash
# Install the package
git clone git@github.com:Gennadiyev/mllm-defake.git
pip install -e ".[dev]"

# Run basic inference
export OPENAI_API_KEY='sk-...'
mllmdf infer --model gpt4omini --real_dir demo/real --fake_dir demo/fake --count 3

# Generate documentation for results
mllmdf doc
```

Use `--help` to learn more about each command.

## Developing

The `mllmdf` entry point is at [`mllm_defake/cli.py`](mllm_defake/cli.py).

### 1. MLLM Classifier

The core of the package is the `MLLMClassifier` class in `mllm_defake/classifiers/mllm_classifier.py`. It provides:

- Prompt-based classification using various MLLM models
- Support for different model backends (GPT-4-Vision, self-hosted Llama, etc.)
- Evaluation metrics and result documentation
- Decorator pattern for result post-processing

For external integrations, `MLLMClassifier.classify` can be used directly. It takes an image path (and label if desired) and returns a prediction.

### 2. Visual Language Models (MLLMs)

Located in `mllm_defake/vllms.py`, supported models include:
- GPT-4-Vision (gpt4o)
- GPT-4-Vision-Mini (gpt4omini)
- Llama-3.2-Vision-Instruct (llama32vi)
- Llama-3.2-Vision-CoT (llama32vcot)
- QVQ Model (qvq)

More models can be added by extending the base class to your needs.

### 3. Prompt System

After months of iterations, lots of overhauls, and a few rewrites, the prompt system is now stable and ready for use. It allows for easy creation of prompts for different detectors, MLLMs and datasets. It is possible to use decorators to interact with the prompt system and modify the prompts using Python during runtime.

The logic of prompt system is implemented within the `MLLMClassifier` class. You may define external decorators anywhere, `./decorators` will be automatically imported.

Here is a template to get you started:

```json
{
    "format_version": "3",
    "name": "simple_detector",
    "conversations": [
        {
            "id": "main",
            "response_var_name": "result",
            "payload": [
                ["system", "You are analyzing an image..."],
                ["user", "Please analyze this image:", "{image_url}"],
                ["assistant", "Based on my analysis..."]
            ]
        }
    ]
}
```

For more complex prompts, please refer to the [`prompts`](prompts) directory.

### 4. API Key Conventions

To mitigate the risk of exposing API keys, environment variables are used to store sensitive information. The variable names are hard-coded in the [`mllm_defake/cli.py`](mllm_defake/cli.py) file, mainly in `load_model` function.

## License

This project is dual-licensed under the MIT and Apache 2.0 licenses. You may choose either license that best suits your needs.
